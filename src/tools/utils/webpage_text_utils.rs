use chromiumoxide::Page;
use serde_json::json;
use std::io::Write;
use tempfile::NamedTempFile;
use tiktoken_rs::cl100k_base;
use html2md;
use reqwest;
use anyhow::{Result, anyhow};
use pdf_extract;
use bytes::Bytes;

pub struct WebpageTextUtils {
    client: reqwest::Client,
}

impl WebpageTextUtils {
    pub fn new() -> Self {
        Self {
            client: reqwest::Client::new(),
        }
    }

    /// è·å–é¡µé¢ innerTextï¼ˆå‰ N è¡Œï¼‰
    pub async fn get_all_webpage_text(
        &self,
        page: &Page,
        n_lines: usize,
    ) -> Result<String> {
        let text: String = page
            .evaluate(
                r#"() => document.body.innerText || document.documentElement.innerText"#,
                json!([]),
            )
            .await?
            .try_into()
            .map_err(|_| anyhow!("Failed to parse text"))?;

        let lines: Vec<&str> = text
            .lines()
            .filter(|line| !line.trim().is_empty())
            .take(n_lines)
            .collect();

        Ok(lines.join("\n"))
    }

    /// è·å–"å¯è§†åŒºåŸŸ"æ–‡æœ¬
    pub async fn get_visible_text(&self, page: &Page) -> Result<String> {
        let script = r#"
        (() => {
            function isElementVisible(el) {
                const rect = el.getBoundingClientRect();
                const style = window.getComputedStyle(el);
                return rect.width > 0 && 
                       rect.height > 0 && 
                       style.display !== 'none' && 
                       style.visibility !== 'hidden' &&
                       style.opacity !== '0';
            }
            
            const textElements = Array.from(document.querySelectorAll('*'))
                .filter(el => el.children.length === 0 && el.textContent.trim())
                .filter(isElementVisible);
                
            return textElements.map(el => el.textContent.trim()).join('\n');
        })()
        "#;

        let result: String = page
            .evaluate(script, json!([]))
            .await?
            .try_into()
            .map_err(|_| anyhow!("Expected string"))?;

        Ok(result)
    }

    /// æ£€æŸ¥æ˜¯å¦ä¸º PDF é¡µé¢
    pub async fn is_pdf_page(&self, page: &Page) -> Result<bool> {
        let url = page.evaluate("() => window.location.href", json!([])).await?;
        let url: String = url.try_into().unwrap_or_default();

        if url.to_lowercase().ends_with(".pdf") {
            return Ok(true);
        }

        let is_pdf: bool = page
            .evaluate(
                r#"
                () => {
                    if (document.contentType === 'application/pdf') return true;
                    if (document.querySelector('embed[type="application/pdf"]') ||
                        document.querySelector('object[type="application/pdf"]')) return true;
                    if (window.PDFViewerApplication || document.querySelector('#viewer.pdfViewer')) return true;
                    return false;
                }
                "#,
                json!([]),
            )
            .await?
            .try_into()
            .unwrap_or(false);

        Ok(is_pdf)
    }

    /// ä» PDF é¡µé¢æå–æ–‡æœ¬ï¼ˆä¼˜å…ˆæµè§ˆå™¨å†…æå–ï¼‰
    pub async fn extract_pdf_content(&self, page: &Page) -> Result<String> {
        let url = page
            .evaluate("() => window.location.href", json!([]))
            .await?
            .try_into::<String>()
            .unwrap_or_default();

        // 1. å°è¯•æµè§ˆå™¨å†…æå–
        if let Ok(text) = self.extract_pdf_browser(page).await {
            if text.len() > 100 {
                return Ok(text);
            }
        }

        // 2. ä¸‹è½½ PDF å¹¶è§£æ
        println!("ğŸ“„ Downloading PDF for text extraction...");
        match self.download_and_extract_pdf(&url).await {
            Ok(text) => {
                if text.is_empty() {
                    Ok("PDF å†…å®¹æå–æˆåŠŸï¼Œä½†æœªæ‰¾åˆ°æ–‡æœ¬å†…å®¹ã€‚".to_string())
                } else {
                    Ok(text)
                }
            }
            Err(e) => {
                eprintln!("âŒ PDF extraction failed: {}", e);
                Ok(format!("PDF å†…å®¹æå–å¤±è´¥: {}", e))
            }
        }
    }

    async fn extract_pdf_browser(&self, page: &Page) -> Result<String> {
        let text: String = page
            .evaluate(
                r#"
                () => {
                    // PDF.js viewer
                    if (window.PDFViewerApplication) {
                        const divs = document.querySelectorAll('.textLayer div');
                        return Array.from(divs)
                            .map(d => d.textContent || '')
                            .join('\n');
                    }
                    // Fallback: visible text elements
                    const els = Array.from(document.querySelectorAll('p, span, div'))
                        .filter(el => {
                            const s = getComputedStyle(el);
                            return s.display !== 'none' && 
                                   s.visibility !== 'hidden' && 
                                   el.textContent?.trim();
                        });
                    return els.map(el => el.textContent || '').join('\n');
                }
                "#,
                json!([]),
            )
            .await?
            .try_into()
            .map_err(|_| anyhow!("Not a string"))?;

        Ok(text)
    }

    /// ä¸‹è½½ PDF å¹¶æå–æ–‡æœ¬å†…å®¹
    async fn download_and_extract_pdf(&self, url: &str) -> Result<String> {
        // ä¸‹è½½ PDF æ–‡ä»¶
        let response = self.client
            .get(url)
            .header("User-Agent", "Mozilla/5.0 (Magentic-mini PDF Downloader)")
            .send()
            .await?;

        if !response.status().is_success() {
            return Err(anyhow!("æ— æ³•ä¸‹è½½ PDF: HTTP {}", response.status()));
        }

        let pdf_data = response.bytes().await?;
        
        // æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ PDF æ–‡ä»¶
        if !pdf_data.starts_with(b"%PDF") {
            return Err(anyhow!("ä¸‹è½½çš„æ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„ PDF æ ¼å¼"));
        }

        // ä½¿ç”¨ pdf-extract crate æå–æ–‡æœ¬
        match self.extract_text_from_pdf_bytes(&pdf_data) {
            Ok(text) => Ok(text),
            Err(e) => {
                // å¦‚æœ pdf-extract å¤±è´¥ï¼Œå°è¯• lopdf
                self.extract_text_with_lopdf(&pdf_data).await
                    .map_err(|_| anyhow!("PDF æ–‡æœ¬æå–å¤±è´¥: {}", e))
            }
        }
    }

    /// ä½¿ç”¨ pdf-extract crate æå– PDF æ–‡æœ¬
    fn extract_text_from_pdf_bytes(&self, pdf_data: &Bytes) -> Result<String> {
        // åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        let mut temp_file = NamedTempFile::new()?;
        temp_file.write_all(pdf_data)?;
        let temp_path = temp_file.path();

        // ä½¿ç”¨ pdf-extract æå–æ–‡æœ¬
        let text = pdf_extract::extract_text(temp_path)
            .map_err(|e| anyhow!("pdf-extract æå–å¤±è´¥: {}", e))?;

        Ok(text)
    }

    /// ä½¿ç”¨ lopdf crate æå– PDF æ–‡æœ¬ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
    async fn extract_text_with_lopdf(&self, pdf_data: &Bytes) -> Result<String> {
        use lopdf::Document;
        use std::io::Cursor;

        let mut cursor = Cursor::new(pdf_data);
        let doc = Document::load_from(&mut cursor)
            .map_err(|e| anyhow!("lopdf åŠ è½½å¤±è´¥: {}", e))?;

        let mut text = String::new();

        // éå†æ‰€æœ‰é¡µé¢
        for page_id in doc.get_pages().keys() {
            if let Ok(page_text) = doc.extract_text(&[*page_id]) {
                text.push_str(&page_text);
                text.push('\n');
            }
        }

        Ok(text.trim().to_string())
    }

    /// è·å–ç½‘é¡µ Markdownï¼ˆHTML â†’ Markdownï¼‰
    pub async fn get_page_markdown(
        &self,
        page: &Page,
        max_tokens: i32,
    ) -> Result<String> {
        // æ£€æŸ¥æ˜¯å¦ä¸º PDF
        if self.is_pdf_page(page).await? {
            return self.extract_pdf_content(page).await;
        }

        // è·å– HTML
        let html: String = page
            .evaluate("() => document.documentElement.outerHTML", json!([]))
            .await?
            .try_into()
            .map_err(|_| anyhow!("HTML not string"))?;

        // ä½¿ç”¨ html2md åº“è½¬æ¢ä¸º Markdown
        let markdown = html2md::parse_html(&html);

        // Token æˆªæ–­
        let limited_markdown = if max_tokens == -1 {
            markdown
        } else {
            let encoder = cl100k_base().map_err(|e| anyhow!("Tokenizer err: {}", e))?;
            let tokens = encoder.encode(&markdown, None);
            let truncated_tokens = &tokens[..std::cmp::min(tokens.len(), max_tokens as usize)];
            encoder.decode(truncated_tokens).map_err(|e| anyhow!(e.to_string()))?
        };

        Ok(limited_markdown)
    }

    /// æ¸…ç† HTML å†…å®¹å¹¶è½¬æ¢ä¸ºæ›´ç®€æ´çš„ Markdown
    pub async fn get_clean_page_markdown(
        &self,
        page: &Page,
        max_tokens: i32,
    ) -> Result<String> {
        // æ£€æŸ¥æ˜¯å¦ä¸º PDF
        if self.is_pdf_page(page).await? {
            return self.extract_pdf_content(page).await;
        }

        // è·å–ä¸»è¦å†…å®¹åŒºåŸŸçš„ HTML
        let content_html: String = page
            .evaluate(
                r#"
                () => {
                    // å°è¯•æ‰¾åˆ°ä¸»è¦å†…å®¹åŒºåŸŸ
                    const candidates = [
                        'main', 'article', '.content', '#content', 
                        '.main-content', '.article-content', '.post-content',
                        '[role="main"]', '.container', '.wrapper'
                    ];
                    
                    for (const selector of candidates) {
                        const element = document.querySelector(selector);
                        if (element && element.textContent.trim().length > 100) {
                            return element.innerHTML;
                        }
                    }
                    
                    // å¦‚æœæ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨ body
                    return document.body.innerHTML;
                }
                "#,
                json!([]),
            )
            .await?
            .try_into()
            .map_err(|_| anyhow!("HTML not string"))?;

        // è½¬æ¢ä¸º Markdown
        let markdown = html2md::parse_html(&content_html);

        // æ¸…ç†å¤šä½™çš„ç©ºè¡Œå’Œæ ¼å¼
        let cleaned_markdown = markdown
            .lines()
            .filter(|line| !line.trim().is_empty())
            .collect::<Vec<_>>()
            .join("\n")
            .trim()
            .to_string();

        // Token æˆªæ–­
        let limited_markdown = if max_tokens == -1 {
            cleaned_markdown
        } else {
            let encoder = cl100k_base().map_err(|e| anyhow!("Tokenizer err: {}", e))?;
            let tokens = encoder.encode(&cleaned_markdown, None);
            let truncated_tokens = &tokens[..std::cmp::min(tokens.len(), max_tokens as usize)];
            encoder.decode(truncated_tokens).map_err(|e| anyhow!(e.to_string()))?
        };

        Ok(limited_markdown)
    }

    /// ä¸‹è½½æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
    pub async fn download_file(&self, url: &str) -> Result<tempfile::NamedTempFile> {
        let response = self.client
            .get(url)
            .header("User-Agent", "Mozilla/5.0 (Magentic-mini File Downloader)")
            .send()
            .await?;

        if !response.status().is_success() {
            return Err(anyhow!("æ— æ³•ä¸‹è½½æ–‡ä»¶: HTTP {}", response.status()));
        }

        let mut temp_file = NamedTempFile::new()?;
        let content = response.bytes().await?;
        temp_file.write_all(&content)?;

        Ok(temp_file)
    }

    /// æ£€æµ‹æ–‡ä»¶ç±»å‹
    pub fn detect_file_type(&self, url: &str) -> String {
        let url_lower = url.to_lowercase();
        
        if url_lower.ends_with(".pdf") {
            "pdf".to_string()
        } else if url_lower.ends_with(".doc") || url_lower.ends_with(".docx") {
            "document".to_string()
        } else if url_lower.ends_with(".txt") {
            "text".to_string()
        } else if url_lower.contains("pdf") {
            "pdf".to_string()
        } else {
            "unknown".to_string()
        }
    }
}

impl Default for WebpageTextUtils {
    fn default() -> Self {
        Self::new()
    }
}